{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig1RLWT11pOX"
      },
      "source": [
        "#Exercise: Text Preprocessing with NLTK\n",
        "Recall that n-grams is a language model that allows us to tokenize sequences of words in a corpora. This is the basis of the language model where we eventually calculate the probability that a word will appear given a history of words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dakJDc6S_iI"
      },
      "source": [
        "## 1. Load relevant libraries and download packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjL4Z_Yw0FsZ",
        "outputId": "fe47ea25-3b8e-4ba2-86b5-998c21527f2b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk.lm import MLE\n",
        "from nltk.util import pad_sequence\n",
        "from nltk.util import bigrams\n",
        "from nltk.util import ngrams\n",
        "from nltk.util import everygrams\n",
        "from nltk.lm.preprocessing import pad_both_ends, padded_everygram_pipeline\n",
        "from nltk.lm.preprocessing import flatten\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rryPOcuM4JZE"
      },
      "source": [
        "## 2. Preprocess the sentences\n",
        "\n",
        "First Tokenize, then add padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xzDPin1z4CRE"
      },
      "outputs": [],
      "source": [
        "n = 3\n",
        "\n",
        "# Step 1: Preprocessing\n",
        "corpus = [\n",
        "    \"I love to eat pizza.\",\n",
        "    \"I love to play soccer.\",\n",
        "    \"I love to read books.\",\n",
        "    \"I love to create algorithms.\",\n",
        "    \"I hate to develop in Java, but sometimes I enjoy it on a Sunday with a coffee.\",\n",
        "\n",
        "]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9H-UjaV4WfM"
      },
      "source": [
        "In natural language processing (NLP), padding is a technique used to ensure that all sequences or sentences in a dataset have the same length. It involves adding special tokens or symbols to the beginning or end of a sequence to make it match the desired length. The n order of n-grams, if it's 2-grams, you pad once, 3-grams pad twice, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l4VBy1J4V4d",
        "outputId": "11147566-48d5-40f5-f2c6-b0dac367bd22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<itertools.chain object at 0x000001FCD884EE90>\n"
          ]
        }
      ],
      "source": [
        "# Tokenize the text\n",
        "tokenized_corpus = [nltk.word_tokenize(sentence.lower()) for sentence in corpus]\n",
        "train_data, padded_sents = padded_everygram_pipeline(n,tokenized_corpus)\n",
        "print(padded_sents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQTYmz_L4mVP"
      },
      "source": [
        "## 3. Create the n-gram model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEOcg-eT5RJi"
      },
      "source": [
        "In the context of NLP, flattening refers to the process of converting a nested list or sequence into a single flat list. It involves combining all the elements from the nested structure into a single-level list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HRWI_2La60tN"
      },
      "outputs": [],
      "source": [
        "model = MLE(n) # Lets train a 3-grams model, previously we set n=3\n",
        "model.fit(train_data, padded_sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TyvcmhvBS3lb"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "detokenize = TreebankWordDetokenizer().detokenize\n",
        "\n",
        "def generate_sent(model, num_words, random_seed=42):\n",
        "    \"\"\"\n",
        "    :param model: An ngram language model from `nltk.lm.model`.\n",
        "    :param num_words: Max no. of words to generate.\n",
        "    :param random_seed: Seed value for random.\n",
        "    \"\"\"\n",
        "    content = []\n",
        "    for token in model.generate(num_words, random_seed=random_seed):\n",
        "        if token == '<s>':\n",
        "            continue\n",
        "        if token == '</s>':\n",
        "            break\n",
        "        content.append(token)\n",
        "    return detokenize(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxtnq0cWS47J"
      },
      "source": [
        "## 4. Generate your test your result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DkFQCnBOS4Z-",
        "outputId": "0f723c1b-70f0-4f57-cd10-96d99ee72835"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'i enjoy it on a sunday with a coffee.'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_sent(model, num_words=20, random_seed=42)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
