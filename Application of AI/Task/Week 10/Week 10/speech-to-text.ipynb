{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract audio from video and get the required time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video\n",
    "video = VideoFileClip(\"2023-02-02 GMT20230203-004335_Recording_1920x1080.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract audio from the video\n",
    "audio = video.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the start and end time (in the format: min:sec)\n",
    "start_time = \"04:10\"\n",
    "end_time = \"1:22:16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the time to seconds\n",
    "start_seconds = sum(int(x) * 60 ** i for i, x in enumerate(reversed(start_time.split(\":\"))))\n",
    "end_seconds = sum(int(x) * 60 ** i for i, x in enumerate(reversed(end_time.split(\":\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut the audio\n",
    "cut_audio = audio.subclip(start_seconds, end_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in ./Audio/2023-02-02.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   0%|          | 0/103327 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    }
   ],
   "source": [
    "# Save the audio\n",
    "cut_audio.write_audiofile(\"./Audio/2023-02-02.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech-to-Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset CUDA memory (helpful if you're running multiple models in sequence)\n",
    "torch.cuda.empty_cache()  # Clear cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()  # Wait for all kernels to finish\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = whisper.load_model(\"medium\") # If you only have CPU\n",
    "\n",
    "model = whisper.load_model(\"medium\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transcribe(\"./Audio/2023-02-02.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" English professor, remember check your answers. At least do not have those simple mistakes, permanent mistakes, like some spelling issues. Once you finish the homework, do a check-in. There are lots of software online or other stuff. You can check the grammar mistake. I guess I have some questions. Do you have any questions? No? Oh, that is the last thing that I found that for the homework too, some of these you have to not submit it. As in the first several weeks, it should be easy for guys to finish it. But for the future, let's say if you go to some projects where you need to start as early as possible, otherwise you cannot finish it. And some students just give me some like, finish the homework in two hours. I mean, this is the first two homework. Please remember to not do it. It is very good to for you guys to start as early as possible. Try to save your time. If you wait until last minute, you probably cannot finish it. Yes, sir. Last week, actually we discussed something about the image format, right? For example, like image representation, data inspection, basic image manipulation, including some basic operations like crop, some image addition, some blending, some histogram. And also we mentioned a little bit about the noise of images, right? Let's try to recap. What about the noises? So the noise could be arrived due to lots of reasons. For example, the light variations, some camera electronics, surface reflectance, the lens operations. And what is the noise? Typically, we just added the noise if I use some data here, right? So eventually the images you guys now have is basically about some images, about some images with a little bit noise. And we have several different paths of noises that we mentioned the last time. So for example, like this is salt and the purple noisy. And this is like the realization of this one for line. And then you have another type that is called Gaussian noisy. Basically just add the Gaussian noise of the original images. And here is the final results, applied the Gaussian noise. And here is the realization of the line in the image. And here is the realization of the noisy in the Gaussian early images. You can see that there are lots of the values in this part, right? So this is a really good results from the Gaussian noisy. So now next question is going to be how can we remove this kind of noisy? Any idea? Is it some filter or what? Filter, what kind of filter? Maybe some filter, some vacancy for origin. Yes, that can be one answer. Any other guess? How to remove the noisy from images? Yes or yes? Put suppressor? Put suppressor. With what? With the suppressor with the frequency What kind of frequency you mean here? Because I'm not sure. And the user is speaking and there is voice. And again, this big to use as voice. But now let's say about the images so easy to imagine how can we use it. Let's talk about images. Also answers. Say it now. Is it now is not you. Also answer. Let's say if you know what it is, we can be. Yeah, that's a good point. If you know what is the function you can subtract the reason why the function. Well, you very close that is the one question that is related to the future. So you will see the letter. So now let's say it was how to remove the noisy. So actually, this is the image. Right. And let's try to realize what is one point. Let's say we run a pick up the center of this, this part, and this is the corresponding to this point. So based on this. You have an idea about this. Example how to remove noisy if you see anything about this numbers, we can average it and put that similarly. Yes, that's a good catcher. So it's similar to the rest of this answer. So we can try to replace the values. It's average. Right. So here is the answer. The answer how about the replacement pixel values with the energy of his network with pixels. So in that case, you already get the information of your network. Right. So let's say let's we will try to cover the filtering and the different kind of correlation and the conclusion, which is very important operation. After that, we will talk about the different kernels, like Gaussian filtering, linear filtering, some n-sharp mark, the image boundary. So eventually we will cover how to remove the noisy image. So let's go to the first part about the filtering. What is filtering? Filtering is a technique for modifying or enhancing an image. It may be used to emphasize the features, for example, motion sharpening and edge enhancement, etc. And also we can use it to remove features from an image, for example, the noisy removal, something that we really want to do. And the filtering is like a neighborhood operation in which the value of any given pixel in the output image is detected by applying some algorithms to the values of the pixels in the neighborhood of the corresponding input pixel. A pixel's neighborhood is the collection of pixels which is rounded by the definition. So let's first realize the example of one big space about spatial domain filtering. Now this part is about original data. Let's say the data we have and this part is about the smooth data we want to get. So replace each pixel with an average of pixels in its neighborhood, so-called moving average. So now let's do one example. Can you guys see some difference in this part about the color difference? Can you see it? So actually how many neighborhoods, for example, for this point, how many neighborhoods it got? Four? So actually it is not that significant, but the answer is five. One, two, three, four, five. It's five. So either way or type it, it's five nearby neighborhood. So that's the measurement that exists in one. So let's take another example. This is the one. What about the next one? Do you see the changes? So you get another one, which is the average of another five neighborhoods. This is a continuum. So eventually we can finish all of that so that you can compare the original data with the smooth data. But do you see the difference here? What are the different differences? The more standardization. Yes, it's more like most, most because now you do not have this kind of, more like an outer layer part. So now the assumption for the average movement filtering is about the true value of a pixel is similar to the true value of pixel nearby or neighborhood. So why is the added to pixel is independent? There is no correlation of noise value added to different pixels. If noisy is just a function added to an image, so we could remove it by subtracting from the function. So the operation is reversible, is related to your classroom. So now question is, is the operation is a reversible or not? If we know the answer. And as an answer? It should be. Why is it, it shouldn't be reversible? Because if we know the noise that has been added, then it should be easy to subtract. Yeah, it can be or it cannot be. So let's say it's a rhythm. That can be true, but the case is we don't know the noise function. But even if we know the noise function, have you definitely got the original? No? Why? What exactly? So we might get near to the original, but we don't know the pixels that exactly needs to be subtracted. Let's continue to see more answers there. As the first answer to this question, so why not? Because the additive noise destroys information and there is no way to recover it. You get the point? So why? I see some confusion. The previous question. Why? The question is, even if you know the noise function, can you definitely recover the original image or original data? I have it here. It depends on the noise function. Even if you know the noise function. Remember the previous question we mentioned about the image. You have an image here that is consistent. This is the original image. Even if you know this noise function, can you definitely get this one? Suppose you already have this one. Can you definitely get the original clear one? Yes or no? It depends on the function. How it changes the photo elements. So what type of function we use? Well, this is any kind of function you already know. You know the function. You know the value of the function. The question is, can you definitely get this I prime here? Yes or no? In an ideal condition, it should give the right answer. It depends on how it's reversing or changing the information. Yes, it's kind of. Let's see what the details are there. So actually, most of the time, you will not be able to do that. The key reason is similar as before. You try to add a few images together. Why? What's the answer? You remember that answer? The pixels are not diagrided. Yes, even if sometimes you know the function of eta, because it's beyond 255, sometimes it still cannot recover the original one. Because the additive may destroy the information. Let's say, for example, the images have finite number of allowed pixel values. Now you can push the pixel values beyond those limits so that it will destroy the information. So even if we have it, the image still cannot be completely recovered. Now, did you get the point? Yes. Good. It's a search. What's the end of the range? Okay. So did you get the point why we still cannot recover it? So now this is a simple equation. Why we cannot get an eyebrow here? Do you know the reason? Yes. You know? Yes. This is just missed here. For example, these images have finite limit of allowed pixel values. So just to specifically give an example, like 255 is the limitation. If let's say you have like, your original image number, let's say you have like 255 as an integer, right? For example, if it is green, you have 200. And together you still have 255. Given the subtraction, you cannot get an x. I guess this time it's better. Okay, good. Let's continue. Here is another case. Let's try to revisit the moving average example. So now instead of thinking it as an average nearby pixel, let's think of this as a set of weights. So weight of all nearby pixels by some kind of weights. So combine all the weighted pixels to come up with new value of pixels. So when all pixels have the same weight, then it is like calculated similar as before. Because previously we treated all of them as equally right. So there is no weight between different points, right? For example, the middle five, we treated them equally in this case. We got this one right. This is the accurate, this mean one. What I have in here, we do not get it. We define a different kind of weight for each point in this case. So this is the general equation in this case. 1r equal to 0 and r i equal to 0, r equal to 2, that is corresponding to here. But if we assign different kind of weight, we might have a different story. So let's think what the details. Notice that the number of weights are usually open. Why? Do we have some quick answers? Why are they always open? For example, we usually take five of it or take three. So why do we need it? Say it loudly. The number of left and right, you said? The number of right and left is equal. Yes, similar like that. The key thing is that it will be easy for you to try to balance your left and right in that case. And we will review that again later about why. So previously we have the uniform weights. Let's say just use one always then divide by the five so that we have this kind of uniform weight. The true value of a pixel is similar to the true value of pixel nearby or neighborhood. So then in this case, we treat them as a uniform weight. So then in this case, we treat them equally. So in this example, we are given some weight to all nearby pixels. But in fact, some pixels are more closer than the other. So in this case, how about giving more weight to the pixels that is more closer? So this is the reason why we want to assign different weights to different points. Let's say if like this point, this should be middle, right? We might need to assign more weights of the nearby examples. Is that correct? I want to pause a little bit. Do you have some questions? This one. Yeah. Okay. Maybe we can expand like use this. You know, it's a file. That's a. This one. Yeah, on the center. So that's good. I saw you in the waste list. So for example, this is the middle. You probably want to assign more weights to this to right. Because you close to the center and we assign less weight to this one. But. Yeah, that's the bottom of the center. So that's the center. So that's the center. So that's the center. Yeah, that's the bottom of the center. Right. You have still a question. The center. The center. For example, you focus on if you focus on this is simple that I write. Yeah, just the center. But that's the center. Yeah, it's never. Yeah, that's never right. Correct. So here is about the results of the uniform weights. And the last thing we tried. Some uniform the weights. Basically means that we will. Professor. Is that if we waited. To know how to filter out the noise. Well, the. The part becomes less smoothly than. Than the average weight. Yes. Yeah. That's a good catch. So let's go back to this. Now uniform weights. So here is the now uniform weights. That is one fourth. And here is the one fourth. The idea is that, So here is the one fourth. Now uniform weights. So here is the now uniform weights that is 1 4 6 4 1, which means that you already in the center you will get the largest number right or largest weight. It is the most important one. So then you will assign two to the left and right and assign one to the one more behind the left one. So the assumption is that more nearby pixel is the more reactive it is and result function is smoother. So now here is a quick like test of guys try to identify which function belongs to uniform moving average and that is 1111 divided by 5 and which function belongs to the non-uniform moving average 1 4 6 4 1 divided by 16. Which one? Because you see you can see three different colors right and this red one is original one and now you need to guess the blue one and the green one. Now let's do a test. What about the green one? Any of you think the green one is uniform? The green one is uniform. Any of you? Raise your hand. Just you. So then I assume all the rest assume the blue one is the non-uniform. Why? Because of the data points. Data points is what? So now this is the red one. You need to pay attention to the red one. Find the red one. So think about if you have this is the key point. If we get a uniform guess this will be what becomes what? This point will become bigger or become very small. Smaller than it should be. Then you can think about the blue one is uniform or not uniform. So now let's do it again. How many of you think about this blue line is uniform? We have four, five? Five this time? Okay, now let's try to get what is the answer. So the answer is yes. The blue line is what? You see it? The blue line is uniform. The reason is that my blue line is decreasing while the original data increase and the vice versa and this issue is that it is affected by the peels on both sides of the original signal. Yeah, same expression as the center of A. So that's this line corresponding to the uniform. Wait, so did you get it for the rest? How many of you know we have? 15? How many of you should remember about which one is uniform and which one is non-uniform? Okay. Questions? Awesome. So next we will talk about the moving average in 2D because we already see the effect of in 1D. So now let's talk about the 2D case. Professor, in the previous time, non-uniform moving average is it not divided by 5? It should be divided by 5. No, so now in this case it's not divided by 5, it's divided by 16. So eventually how many was the total number of it? 16. Right, so that's the reason why it's divided by 16. But it does not belong to a non-uniform moving average. If it is average, then it should be 5. You need to see about the weight. What is the total number of weights? There are 5 weights. And as you mentioned, it has to be an odd number. Old number just means this is the 5. 5 means old number. Old number means number of weights. So you have 5, right? It's not by 16. This 16 you just get it by the sum of these different weights. Even divided by 16, you still have different non-uniform here. So this point in the center will be always important to the arms. Here is about the 2D case. The 2D is more like just one extension of the moving average in 1D. So let's say this is just an image. So the black one is just all zeros, right? And then in the center we have all other identities of this piece of number. Let's say we want to do a moving average in this case. So what will happen? What is the average of this one? 0. Yes, definitely 0. What about this one? It's 10, right? And again, 20. Oh, we should get it right? Why is it 20 years? 21. 21 years. Okay. What's the name of the black one? Irish? Is that your name? So why are we getting it? Why are we getting it? Good. Yes, so now you guys really get it. And similarly, it comes through from left to right-handed so that eventually we get a 30 here, right? So let's continue. Eventually, once we finish all of it, you get a different kind of image. So now it's kind of like a 2D moving average. So the left part is the original image. So now after you perform the average, you can get another kind of image. And eventually it becomes like this. It's a little bit fuzzy compared with the left one. And here's just another notation or donation of it. Let's say if we times with like 1 over 9 times with always, so you will get a similar kind of image like this. Let's see what's going on with this kind of photo. Okay. For all my students, can you see my screen? Yes. Yes. Sorry, Professor, we can't hear you. I just wanted to talk. So now really we are needed to talk about a mass of moving average. That is more like a correlated filtering with uniform weights. So the mathematics method that we discussed previously is so-called correlation or the correlation filtering with the uniform weights. And there's an average window size like is about 2K plus 1 times 2K plus 1. If K should be, this two should be here. If K is equal to 1, it should be 3 plus 3 matrix. If K is equal to 3, so then it should be 7 by 7 matrix. And here is the bunch of the stuff that you need to pay attention to. So eventually about this is the key equation that you guys probably need to remember a little bit. So this is eventually how we perform the 2D image. And this term is so called it means to looping over all pixels in the neighborhood around the image pixel FIJ here. And basically is to the similar stuff that in the previous example we just discussed, right, from level to level. From top to the bottom, it will loop all the image. And in this case, the ZK plus 1 square, this term comes into the uniform weight for each pixel. For K equal to 1, they should be 3 by 3. And then this way that we are divided by 1 over 9 should be similar as previous example. And the edge here, let's talk about another case about non-uniform weights. So different weights depending on the neighborhood pixels relative position. So more ways to close out pixels or averaging or further with non-uniform weights. So this is called a cross correlation or correlation or donated by G that is equal to edge times F here. And eventually this is about donation. And this actually is so called non-uniform weights. Also we can name it as mask or kernel, blah, blah. And actually UB here is also referred to with many terms, as we mentioned, and also we can mention as coefficient. So in fact, just a matrix of different weights. This one? Yes. This should be, sorry, there's a mistake here. This should be equal. QK plus 1. And here is similar that the donation as the previous one, this is just the lesson of it is really about the image F, X, Y. So then the subcoding comes with the edge UB. So you can get the G, X, Y again. Here is about another example of the ice. As a first the series results, then I will try to run the code with you guys. This should be your homework. You will have some time to practice it today. As I see the eye, so that is the original image and the right hand is uniform filtering average or average image. Do you see the difference? It's difficult, right? It's very difficult to see it. If you choose the kernel size, that is more. Let's say just even by one by one or two by three, they're very difficult to see that you have a scale. Unless you see the original image, you have lots of kind of random noisy. So you can remove it. And this is about non uniform filtering. So you can see some results of them. Let's try to see the code results here. So this is the result. So for our eyes, we have the average code that you find the difference. Excuse me, Professor. What is the difference between the non uniform filter and the uniform filter? So this is the edge of the BNV. In this example, it will be very difficult to see it. But we will see about the non uniform and uniform. So in this case, let me try to explain the code a little bit. For those parties, this is a reader image, converter image, the query image, then resize it, then we will show this image. For the uniform weights, this is the uniform weights that we get, right? So that you will apply this image filtering this function. So that you get this one. This is the results. For the results we already see. And then here is the non uniform like this one. You will apply another function called the image filtering, but you use a mask too. This is about non uniform. Although from the image itself, it is very difficult to tell the difference. But maybe after class or in class, if you guys have time, you can try to subtract the results from these two. This average image minus with average image too, you will find a small difference between these different uniform or non uniform weights. The answer is yes, there is a lot of difference, but it will be very not significant to observe in our case. Okay. Let's continue. The filtering of the impulse signal image is the same as before. So now we, once you have an image as one, so then it comes with this kind of kernel or weight, the ABC. So first of all, we probably will get this one as all zero, right? About this one, you will get that. And let's continue to do it. That's what will be happening in this case. We are doing more. And eventually we will finish. Did you observe some difference? It does make me think it was the inverse, right? I get a feeling a little bit about after two components kind of kernel, right? The conclusion is that filtering and impulse will output a flip of kernel weights, right? It's a flip. But why did the value did not divide by the input? Because the input is the same as before. But why did the value did not divide by nine? So in this case, it's not necessary just to divide by nine in this case. And this is another operation that is called the impulse signal. It's not always like divide by nine. Previously we divide by nine so that we want to give all of them like the same kind of value. In this case, it's the ABCDEFGHI. We want to show what are the effects by filtering kernel. It's different purpose. Okay. Even if you divide by nine, let's say whatever happened, A divided by nine, B divided by nine, C divided by nine. You get the same conclusion here, right? Does that answer your question? Yes. Sure. Yes. Okay. Thank you. Professor, I can hear you. No, I still can't hear you. Can you hear me now? Yes. Yes. Okay. Yes. Okay. Let's continue with this. Yes. Previously we just mentioned that the convolution also is very similar to the correlation. So the only difference is about the flipped kernel. Let's say about this case. You have this H1, H2, H3. So then the X-flip is just in this way, is that correct? This X-flip. Is there a difference between these two cases? Which way it is? Yeah. So what about the Y-flip here? It would be this way, right? Yeah. So, this is the Y-flip. And eventually it comes with this one. So now you can see that similar to the correlation, as again, there are two loops well over the rule and the other over the following. So this is just a whole different situation. And for example, eventually, now let's say, what is the result? Half time moves H here. So this should be F1 times H9 here, right? Should be different from this one, right? So, the point is still kind of a ten. But we can't get it wrong. So let's say for a year, the convolution is equal to the correlation. Then the kernel will get symmetric. The experiment on the human processing unit kernel is symmetric. That is, for example, my question. The H-flip will not make a difference. It will make a difference on the vertical and horizontal edges. But the function is the same. Let's talk about the image kernels. A kernel of convolution matrix or master is a small or weight matrix. It is used for blurring, sharpening, deposing, edge detection. The blue will cover the blurring and sharpening. And maybe in the next week we will talk about edge detection. How it can be used on simple image kernels. So the above mentioned tasks are accomplished by three art solutions. Two art kernels and an image. So, the first is to introduce the foundation that we mentioned earlier. Now let's pick a basic paradise. The plural of single peaks into a urban spot. What we need to filter is the spot. Should the weight do like a three by three square uniform width? Or should the weight time be with an 11 by 11 square or uniform width? Or we can use something that looks like a plural of five layers falling off. So, what we need to do is to filter the area of the image. So, we need to filter the area of the image. So, we need to filter the area of the image. So, we need to filter the area of the image. So, we need to filter the area of the image. So, we need to filter the area of the image. So, we need to filter the area of the image. So, we need to filter the area of the image. So, that's the one. So, why is that one? Yes, it's kind of awesome. Let's see the details. Let's say you can use like three by three. What will happen? That we are given equal weights to all the pixels. And then it's a sphere we are just producing a block of artifacts. And for 11 by 11 squares, beautiful weights, we are getting some harder boundaries of what artifacts are given. So, that's the first example. The solution is that try to get something like a spot. But definitely you need to have some higher values in the center. Low values to the edge. Let's see how this example of the image. It's similar. It's similar to your picture. So, you start with the center of the image. That's the beginning. That's the beginning. That's the beginning. That's the beginning. That's the beginning. That's the beginning. That's the beginning. That's it, we're choosing the center. Kind of alright. Let's look at another type of partial filters. The value effects of this blurring technique is as small as blur, where resembling that of real images through the transverse screen. This is our next slide. The cultural composite is also used as a proof of the stress stage in the visual algorithm to see how the different scales work. For our human, we have a sphere that can form similar as the question piece. The nearest number of pixels also have the post difference for the cultural period to occur. So as you can see this is one example. So in the center is more important on the edge. This is a approximation of cultural functions. The function is either as distributed by stream, or as a sphere that captures in the center as a whole weight system either forced up to the edge. So here is about the notion function. And I should end with that. See here my just a little bit of explanation. Here is just an approximation of the kind of notion function to eventually form an image. Here is this kind of function to form some process. And this is another view of the notion function. And here is this kind of small line of code we have of the notion function. Let's say we have a question function. First we need to create an image, resize it, and by using this kind of algorithm we have a special function with size that we can build in and continue getting some. But the very new image is the less safe kind of function. So this is the result of kernel cycle 31 by 31 with sigma equal to 1. This is sigma equal to 5. This is sigma equal to 13, this is sigma equal to 17. But what are the changes here? So the skin really changes. The blurring starts like this. What about the practice with linear filters? What about the output? What about this? Just say you get the same as the other. The another one is the blurring. So what kind of gap do we get in this case? What do we want? What do we want? Box? What the box is? So let's say we want to get the same as the other. So what do we want? What do we want? Box? What the box is? What do we want? So let's say this is the other thing. So imagine a community that has an impulse of output. 7, 5, 5. Do you notice one of our previous questions? You can run more of that. You eventually just get the same. It's just the 5 and the center. Not sure. That's it. What about this one? Let's try to say you do not see the answer. What is the answer for this one? Say that I said the lovely? You said it's a blip. Okay, casual. What about other answers? Say, did you see the answer? What is the answer? Okay. So actually, we are shaped by the one pixel. It is not a blip because of the missing side. Because of y in the right hand correspondingly. The previous because of y in the center. Even if you blip it, it's not a change in anything. However, in this case, because of y in the right hand, the blip is kind of a different thing. Which is a very important. And then your program is multisymmetric. And then you change y in the center. Actually. What about this case? Interesting findings. Do you need some explanations here? What does this operation mean here? So actually, this is the original image. This again is the original image. This is also the original image. Can you guess what will happen? Yes, this is minus. Let's think about maybe you guys have like five pictures in your screen. Think about this also. That one we already discussed. Whether we can get the findings from the standard operation. Is it quick or no? Do you need it? Yeah. I think that's the answer. Okay. So, I think that's the answer. Okay. So, I think that's the answer. Okay. So, I think that's the answer. Okay. So, I think that's the answer. Okay. So, if you guys could just drop the light here. Yes. Okay. So, one by one give three seconds to the audience. And I'll still go into one by one. That garlic missing. Sorry, Professor, we can't hear you. Yeah, go ahead. No, let's get a study yet. Sometimes it's kind of always really annoying. That's the reason why guys need come to class. I hate to hear so well be this image get the worst or get better. It will be expected. Yeah. Okay. Let you guys discuss a little bit. Maybe we can get started. Okay. Say that again. Overlapping image. A lot of work. This will be. This is the back of the left. Then this particular will get this particular entire output. Yes, that's true. You say. You say a little bit larger. What about other answers. The contrast will be. Increased or significant lower you say you're below. Okay, three different words here. So now let's just try to discuss whether we can get from. That's what about this one. What was this one. It's very difficult to see right now. This is something here. It should be very kind of difficult to write. I see something. You bet I can see something. It should be something there is just very difficult to say. So eventually we are trying to get something. Little bit. How do you say it's like a shop shop the image. They'll be shot. Or you can see a more more like like. So this method actually is a part of. The image. So there are micro ways to blur your image. In our case, we use the average. Let's say. With the details of a shop. The shop must be used. Is used to sharpen an image. The. The sharpness of the image. The sharpness of the image. Is used to show that it improves the definition. Fine detail. Or as a high frequency components. Is our original image. So the name. So here is the best. So the sharpness of the image. Is the same as before. So the sharp image is equal to. Original image. Minus the blurring image. So it should be similar as the previous example. Right. Here. The original image. High frequency. High. This is about. The results. Here. You can compare the difference between these two. So this is the average. Image with the mask. And. Here in this case. We will try to recreate a Gaussian mask. With a nine by nine. And sigma equal to five. And here are the details. Let's see whether we can see some difference between these two. You see. You did find some differences. Although it's tiny. You can still see there. And then we try. To see more examples in this case. What we can get. This is the original image. And this is the most. High frequency component. And the sharpness of the image. This is the original image. And this is the most by five by five. And then we can get this is the minus. The difference. This is the so-called details. Now you can see. The difference between those two. Let's try to. And this is the detail. Traction operation is also called. High pass filter. Let's try adding them together. Specifically. And then we can see the difference. Between the two. So that you will try to improve it for nine times. You mentioned. So now you can see the difference between. Original and the sharpness. Now this is. Significant in this case. What is. What is. What. Efficient. It cannot be. Efficient. But it's the other answer. So now it's just a privacy. Another kind of number that you will. Try to increase the details. Or how many times. Right. Is it big. I hope. I will. Call it as a weight is just. About. Parameter like. It is not a constant. It is just a number that you can change. It's not a constant. It's afraid. Just apparently. So eventually. We'll get different. Sharpening. And then here's the overall. Like. Previous problem. That is. Is already. And. This is the. The. And then you can. Expand it. And now. This is. A unit. In. Identity. With a single one. As wise. So this is something that we can. Donate. Effect. The. Left. Is about. And. Is like. So eventually. So this is. This is the results that we can get. About. You got it right. Great. And then here's another. Comparisons. And the. About parties. By the. So this is about. So after. You can see. So you can see this example. You really can see. And. And here's another one. This is very blurry. Sometimes you cause that. Of the camera. This can be caused by. And then. And. Like. For example. This camera. This is. And then. And you. The. It is. Operation. a commercial operation eventually you have a different effects of your images right uh another kind of simple filter is called a threshold which means that you will just sign a different the threshold if it is bigger than some threshold you will treat it as a one number if it is smaller another one you actually another number so here is the details so let's say for the m here is bigger than a we will treat it as 255 if not it's just a zero so eventually it becomes what kind of image binary image right so like kind of segmentation right so actually in the early stage before the popular of the give rating we will just use this kind of threshold the best method try to segment some images for example even let's say if we care about this man another man this female in this pattern we really use this kind of so I hold it try to get the boundary of this human right this is the simple of the threshold and then for some images either will be very useful especially there are significant contrast between the pixels here the threshold can be a good way to do it. And then we have more examples here so now let's try to say dealing with the image boundary so one issue is that it comes up when filtering an image is how to deal with the image boundary as it is not possible to fully place a kernel on the image to produce a new pixel value or what happens when kernel filters of course off the edge what does this mean so you let's say if you have an image size of four by four your kernels are in three by three what about the case what about the edge can you filter the rest one where you lost someone yeah you will try to we have lose some edge information right and here are some couple of probability possibilities so for example you may need to choose the clip filter or black assume pixel pixels outside our image frame are the black so that's apply applying a filter image so that's apply applying a filter image as darker at the edges so in this case maybe difficult to say there but you can treat treat the outside as black right this is the one answer how we handle the case analysis that we were trying to work around what does that mean it means that you try to apply Fourier analysis processing in frequency domain that assume that the image works around for example the signal or alternates and the source signal at the end is similar as it was at the beginning so which means that you will try to you know copy to another wrong right so that you are seeing the other similar this is really about the copy this is what really means about them for the images that like a kernel flip or like use another circular case so that you can get more details another one is called copy edge or replicated that we are extends the out of the boundary pixels as i said either we are like try to copy another line of pixels of outside and we have another one of the reflect across edge or symmetric they try to reflect the edges to some extent the image and up to now we already have all those important parts from filtering at different kernels the relation and kernels so rest we were talking another important part that is about the noisy removal so let's see the details of it so we began this model with discussion of noisy removal and they discussed the caution noise the caution filtering and the uniform weight average the caution filtering may not be able to remove noises that doesn't follow caution distribution in terms of proper noise for such a case we needed to use a non-linear filtering what about this case this is the original noisy images that you guys probably already did that right so after you perform the get some caution filtering images then times caution mask and let's say three by three kernels by sigma is equal to one and for example this is the energy image with this kind of mask the uniform mask and then you can see the difference between the two images so this is the original noise the uniform mask so now again let's try to go back to the question how to remove this noisy and somehow you already mentioned that we probably needed to take as some kind of energy of these surrounding pixels right let's see what's the what are the effects of it now consider those pixel values with the center pixel with the high values like the sort of noises or is the average of those values is a good option to remove the peak on noisy is the good one why so if we have a so what about this by everything with this mask so the center pixel was about replaced by the 48 so now is this case do you feel it's better yeah yeah so how about using some medium value of about to have more operate to base the medium we are selecting base that is presented in the neighborhood unlike as an average value so what he sees that the image of pixel values in the neighborhood doesn't change in abruptly unless it is an edge right so medium values let's say if we want to see the medium value of it so we first need to solve those values right and then we will try to pick as a medium there so what is the medium value here is 27 right so then more likely to use 27 to present this kernel do you feel it is better yes it's kind of a much much better than previous one right so the results of applying medium filtering so the medium we are selected for example previous 127 that is presenting the neighborhood unlike average value so medium filtering is nice as it removes the spirals and the e plus with value from the neighborhood and the medium filtering is not a linear one so that is something that we want to get and the left again is the original noisy image and the right hand is a caution filter the image use the difference here you see it is blurry or it's better is the body of better what about this one do you think this is better or it's just a bad yeah yes that's correct it has reduced some noise in body and simultaneously a little bit blurring here right what about this medium filter do you see the big change what are the advantages here yeah right so that's even if you try to use this some medium filtering because definitely firstly we are removed by some nearby pixels right you cannot let's say you not only want to get a very high resolution image but also the one you remove noisy so sometimes it will have become difficult so nowadays unless you use some very deep neural network you can achieve this kind of process for this kind of medium filtering because it is very easy method right so we cannot get a very high resolution image and here the details of the image maybe i can show you the letter about our different codes so first this part about the caution filtering that is and this is about uniform weight and this is about the medium filtering so let's see we have some we have the slides of our and let's have you see from the code so so this is the original image here's about the same this is some changes here all right this is from the previous example it already got a blur about applying the caution filtering there okay now here in the case of the sharpen image and not just one example here is another one and then this is the case is that you guys also need to reproduce as your homework so you will see it later here so this part is about the original image and here is about the caution filtered image and here is about uniform the image and this is eventually about the medium filtered image do you see the difference between them and also let's try to compare with this one yes you may more likely choose the medium filtering as your kind of master schedule you're like purpose of all your devices right now and then to be honest even nowadays for some images we still try to use medium filtering to remove a noisy because typically for those deep learning models they are usually useful for some kind of images some images are in the paper but if you apply to the real world some images the performance will still not that good and especially if some of your background of physics if you try to design some system to collect the images they still need to collect a bunch of images then try to heritage them together so that they can remove some random noise okay let's see what's about masterizing as you guys like to buy your guys homework and you guys I believe you should bring on that part of this time right now you are really complaining with it okay you can start me so now try to refresh the page to see whether you can see the almost three there and let's see whether you guys have some problem with that is vice or more estiver a website and then you can ask your classmates how they handle with this with their phone to do some homework. Maybe asking that your iPad also have what you've featured. Like you did last time. Okay, good. Can you guys see the homework? Yeah, yeah. Good. There are a few tasks. Let's try to, let me try to explain a little bit. So first task you guys need is to apply the energy filtering of the image. The second one is to apply the image filtering of the image. I want ways this kind of uniform ways and then not uniform ways. This should be simple, straightforward, right? The second one you guys need to apply a Gaussian function. And the third step is that you guys need to apply the Gaussian image filtering of the image I to the dash one here. And then the last one you guys need to apply some different filters here. And then you need to apply some different filters here like the Gaussian filter, the uniform filter, and the medium filter to realize whether the guys can get some results of the image analysis. Okay. All right, do you have any questions? Are there only three ways in which we can remove the noise? Say it again. Are there only three ways to check for noise? Oh, you mean are there only three ways? No, definitely not. There are lots of other kind of filters you can do that. So now, as in the class, we already discussed this kind of three different typical filters. I want to go and see if you can recover it or what's the performance of it. And then eventually there are also different other filters like, for example, maybe some filters may be focused on the edge detection. There are lots of different filters. Because a filter can just mean like, for example, in 3x3, like if you want to detect some edges like maybe just the one in the diagonal, there are lots of other filters. It's not just that here. I think you want to remove the noise. I would say those should be used for the traditional methods. This is a traditional one. Okay. For those students who do not have some reach, send me the home assignment to you. Do you have some questions about assignment to? Oh, you just did not finish it. Okay. This one. The previous question. Okay. I will ask it just open CV is enough. This one. Okay. Okay. Okay.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the transcription to a text file\n",
    "# Save the transcription to a text file\n",
    "with open(\"./Transcript/week3.txt\", \"w\", encoding='utf-8') as text_file:\n",
    "    text_file.write(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the model and clear CUDA cache\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()  # Wait for all kernels to finish"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
