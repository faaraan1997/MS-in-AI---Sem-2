
[
    {
        "transcript": "So now let's get started with our this lecture with today, we will talk about the logistic regression model and the list of scripts. Hopefully, we can cover all of it.",
        "week": 4,
        "page": 1
    },
    {
        "transcript": "Last week, we briefly mentioned about the differences between the regression and the classification. I know we talked about the linear simple linear regression, the multilinear regression, and, the polinomial regression. We also mentioned several metrics regarding the regression problem and the classification problem. What are how do you use the metrics for the classification problem? I remember? What kind of metrics that, we quickly used was a classification problem?",
        "week": 4,
        "page": 2
    },
    {
        "transcript": "Today is not from previous class. And here is outline that we will briefly mention about classification problem again, and, we will try to answer the question why not use linear regression for classification problem. And then we are very good at details of a logistic regression. For example, how the how this is representation And some cost function, but just the regression is a gradient descent and the regularization, and then we're gonna talk about Least Squares regression.",
        "week": 4,
        "page": 3
    },
    {
        "transcript": "So first, let's review about the classification problem again. So, typically, if it, is a binary classification, then we have 2 classes. Right? We will use 0 to the negative class and Google values 1 to represent the positive class. There are several applications. For example, in your email, detect whether it is a spam or not spam. In a medical part of also, we want to identify whether it is a tumor, whether a Alright. So we want to identify whether it is a tumor, whether the tumor is and for the bank transaction, we will detect whether it is fraud or no fraud. Right? Yeah. Several examples about Classification binary classification problem.",
        "week": 4,
        "page": 4
    },
    {
        "transcript": "As a review about linear classifications that we discussed last week. So in this example, We have so many different, lines here, and those lines I can't what? This this nice are what? Yes. It is a regression line, but we do it for this at the hyperplane or we call it to call it You see your boundary is fine. Yeah. I mean, the left hand, we actually give 1 class. You read it on our side. We actually do that as the class 2 here. Right? Why?",
        "week": 4,
        "page": 5
    },
    {
        "transcript": "We mentioned the problem of it is not, yes. That can be Yeah. That's the one point about here. So, actually, we work out all the detail. What kind of new districts? Distribution? Okay. Yeah. That's gonna be another I'll set up for it. Right here, we not one is a linear regression.",
        "week": 4,
        "page": 6
    },
    {
        "transcript": "So now give an example of the tumor size and the malignant to see whether the tumor is malicious also. So now let's say if we want to use a linear regression, you feel these data points Where is the log? The line should be this way or should be this way? Should be this 1, or should it be this 1? Which way? You see it this way? 1. Right? So, actually, so you guys need to notice that. But in your regression, we actually want to figure that once. We want the data points that are close not the line are close to the data points. Right? So, typically, we will use this as the linear line That I cannot point to right because it defeats lots of points. Right? Because this is the regression line you guys made, can calculate to fit those given datasets. So let's say in this case, We had defined as railroad, right, was, linear regression, and, I just did the s here, miss the to predict as 1. If not, we will just predict as 0 here. So let's say sphere is a spherical 0.5. So which part is negative 2 and which part is positive? It's kind of negative. Right? So now let's see more details. So, actually, we'll be able to use this line as the handoff of our decision boundary. Right? So if we get below the 0. 5, we recognize this part as negative. If it is bigger than they're quantifying those parts or those core points where we are saying it is quality. So in this example, we may think that this behavior, where should we be to norm for it to buy?",
        "week": 4,
        "page": 7
    },
    {
        "transcript": "However, let's see another case. So this is similar as before. Let's say we have another outlier. So now for linear line, Yeah. It's for this guy this time. It's nice. But be close to this point. Right? You guys learn about linear regression. Right? Right? So now in this case, we're kind of well, this 3rd line should be close to this point. Right? Because, you know, one fits all the data points. But now did you notice something different Here. So let's say we still want to use the previous 0. 5 as the threshold. So no we're changing. The answer is here. So if we feed the best from the regression line, The scale wouldn't be not to decide any point by which we can differentiate the classes either way of putting some positive class examples into negative classes. So in this example, what 10 points will be pushed to the left team In this case, I'm advised. So now 7. 7 points? This is 4, and you have another history. Right? So, actually, you will put these 3 points where Previously, it should have been in the positive classifier. So in this case, here is the DCM boundary. So in this case, it will run move to the negative points. So in this case, the linear regression did not do a good job. Right? Because this is the key reason why We don't want to use linear regression, but classification problem, because either we are affected by outlays a lot.",
        "week": 4,
        "page": 8
    },
    {
        "transcript": "So let's let's talk about logistic regression. So logistic regression is one of the basic and the popular algorithms to solve a classification problem. So let's say in the future, you can review and ask a question about what is the  usage for the Not just a regression. It is about regression problem, or is it look like classification model? If you say the but just a regression is very important question problem, it's known as a logistic regression because its underlying technique is quite the same as linear regression, And the term logistic is taken from the logit function. That means they use this method for classification. Okay. Good function. So after x is between if you want 0 and y should be between use in any natural number. So let's say, what is the range of the margin? The logic function. What is x range? X range is That's the entry. 0 to 1.",
        "week": 4,
        "page": 9
    },
    {
        "transcript": "So now let's go review about the previous classification. So even in final classification, we have one as positive and 0 as negative. So is that the case? Let's think about the previous linear regression model. So Is that right? Okay. Yeah. So, Zelle, what about the logistic regression? So, actually, we want the output is between 0 and 1",
        "week": 4,
        "page": 10
    },
    {
        "transcript": "Any guess? So that's what we do. So that we can gather a interval between 0 and 1. Any guess? No? So previous, this w x as p can be any number. We can do what so that it can be between 0 and 1. It's kind of so, actually, once I point out, you guys can't remember. So this is very about this And this function is the so called sigma function, or we call it the HABDA, not just the regression.So I think, up to now, you guys will No. What do we needed to do to apply for is, live at addition, what's a single function for linear regression.",
        "week": 4,
        "page": 11
    },
    {
        "transcript": "Right? So that I need to change this in between adjust the regression. And then eventually, we have to make it as the h x here as the one divided by 1 plus e minus the c negative times with x. But this part this part is really about the z y, but the z is dominated in this sphere about the z g(x). Right? Let's continue.",
        "week": 4,
        "page": 12
    },
    {
        "transcript": "",
        "week": 4,
        "page": 13
    },
    {
        "transcript": "",
        "week": 4,
        "page": 14
    },
    {
        "transcript": "",
        "week": 4,
        "page": 15
    },
    {
        "transcript": "",
        "week": 4,
        "page": 16
    },
    {
        "transcript": "",
        "week": 4,
        "page": 17
    },
    {
        "transcript": "",
        "week": 4,
        "page": 18
    },
    {
        "transcript": "",
        "week": 4,
        "page": 19
    },
    {
        "transcript": "",
        "week": 4,
        "page": 20
    },

]


